{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud services enable ml.googleapis.com\n",
    "!gcloud services enable compute.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘friday_training’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir friday_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch ./friday_training/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/home/jupyter/.local/lib/python3.5/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/jupyter/.local/lib/python3.5/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./friday_training/train.py\n",
    "import datetime\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import subprocess\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from math import sqrt\n",
    "import datetime\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Fill in your Cloud Storage bucket name\n",
    "BUCKET_ID = 'friday_demo2'\n",
    "\n",
    "public_bucket = storage.Client().bucket(BUCKET_ID)\n",
    "blob = public_bucket.blob('Data/train.csv')\n",
    "blob.download_to_filename('train.csv')\n",
    "\n",
    "blob = public_bucket.blob('Data/test.csv')\n",
    "blob.download_to_filename('test.csv')\n",
    "\n",
    "#Read the data from the bucket\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "numeric_features = train.select_dtypes(include=[np.number])\n",
    "numeric_features.dtypes\n",
    "\n",
    "\n",
    "# categorical columns\n",
    "categorical_columns = [\"Product_ID\", \"Gender\", \"Age\", \"Occupation\", \"City_Category\", \"Stay_In_Current_City_Years\",\n",
    "                       \"Marital_Status\", \"Product_Category_1\", \"Product_Category_2\", \"Product_Category_3\"]\n",
    "\n",
    "\n",
    "# Join Train and Test Dataset so it can be cleaned all at once\n",
    "train['source']='train'\n",
    "test['source']='test'\n",
    "\n",
    "data = pd.concat([train,test], ignore_index = True, sort = False)\n",
    "\n",
    "#imput the value -2 for NaN since NaN most likely means that the person did not buy products from these categories\n",
    "data[\"Product_Category_2\"]= \\\n",
    "data[\"Product_Category_2\"].fillna(-2.0).astype(\"float\")\n",
    "\n",
    "data[\"Product_Category_3\"]= \\\n",
    "data[\"Product_Category_3\"].fillna(-2.0).astype(\"float\")\n",
    "\n",
    "#Get index of all columns with product_category_1 equal 19 or 20 from train and remove since not populated\n",
    "condition = data.index[(data.Product_Category_1.isin([19,20])) & (data.source == \"train\")]\n",
    "data = data.drop(condition)\n",
    "\n",
    "\n",
    "# convert categorical data to to numerical values.\n",
    "# convert data in categorical columns to numerical values\n",
    "encoders = {col:LabelEncoder() for col in categorical_columns}\n",
    "for col in categorical_columns:\n",
    "    data[col] = encoders[col].fit_transform(data[col])\n",
    "\n",
    "#create count features of each user\n",
    "def getCountVar(compute_df, count_df, var_name):\n",
    "    grouped_df = count_df.groupby(var_name)\n",
    "    count_dict = {}\n",
    "    for name, group in grouped_df:\n",
    "        count_dict[name] = group.shape[0]\n",
    "\n",
    "    count_list = []\n",
    "    for index, row in compute_df.iterrows():\n",
    "        name = row[var_name]\n",
    "        count_list.append(count_dict.get(name, 0))\n",
    "    return count_list\n",
    "\n",
    "data[\"Age_Count\"]  =getCountVar(data, data, \"Age\")\n",
    "data[\"Occupation_Count\"]  =getCountVar(data, data, \"Occupation\")\n",
    "data[\"Product_Category_1_Count\"]  =getCountVar(data, data,\"Product_Category_1\")\n",
    "data[\"Product_Category_2_Count\"]  =getCountVar(data, data, \"Product_Category_2\")\n",
    "data[\"Product_Category_3_Count\"]  =getCountVar(data, data,\"Product_Category_3\")\n",
    "data[\"Product_ID_Count\"]  =getCountVar(data, data, \"Product_ID\")\n",
    "\n",
    "#Divide into test and train\n",
    "train = data.loc[data['source']==\"train\"]\n",
    "test = data.loc[data['source']==\"test\"]\n",
    "\n",
    "#Drop unnecessary columns:\n",
    "test.drop(['source'],axis=1,inplace=True)\n",
    "train.drop(['source'],axis=1,inplace=True)\n",
    "\n",
    "# remove column we are trying to predict ('Purchase') from features list\n",
    "train_features = train.drop('Purchase', axis=1)\n",
    "test_features = test.drop('Purchase', axis=1)\n",
    "# create training labels list\n",
    "train_labels = (train['Purchase'])\n",
    "test_labels = test['Purchase']\n",
    "\n",
    "# load data into DMatrix object\n",
    "dtrain = xgb.DMatrix(train_features, train_labels)\n",
    "dtest = xgb.DMatrix(test_features)\n",
    "# train model\n",
    "bst = xgb.train({}, dtrain, 20)\n",
    "\n",
    "\n",
    "# Export the model to a file\n",
    "model = 'model.bst'\n",
    "bst.save_model('./model.bst')\n",
    "\n",
    "# Upload the model to Cloud Storage\n",
    "bucket = storage.Client().bucket(BUCKET_ID)\n",
    "blob = bucket.blob(model)\n",
    "blob.upload_from_filename(model)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Booster' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7570f6205164>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "bst.fit(train_features, train_labels)\n",
    "y_pred = bst.predict(dtest)\n",
    "acc = accuracy_score(test_labels, y_pred.round())\n",
    "print(acc, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred.round())\n",
    "print(acc, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Define a timestamped job name\n",
    "JOB_NAME = \"friday_training_{}\".format(int(time.time()))\n",
    "BUCKET_NAME = 'friday_demo2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [friday_training_1564604710] submitted successfully.\n",
      "INFO\t2019-07-31 20:25:15 +0000\tservice\t\tValidating job requirements...\n",
      "INFO\t2019-07-31 20:25:18 +0000\tservice\t\tWaiting for training program to start.\n",
      "INFO\t2019-07-31 20:26:34 +0000\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"127.0.0.1:2222\"]} --task={\"type\": \"master\", \"index\": 0} --job={  \"package_uris\": [\"gs://friday_demo2/friday_job_dir/packages/1954ba646e37bebd919cb50e2e5f2c36fcba8f4c7a713346c38b2c477223f738/friday_training-0.0.0.tar.gz\"],  \"python_module\": \"friday_training.train\",  \"args\": [\"--bucket-name\", \"friday_demo2\"],  \"region\": \"us-east1\",  \"runtime_version\": \"1.12\",  \"job_dir\": \"gs://friday_demo2/friday_job_dir\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.5\"}\n",
      "INFO\t2019-07-31 20:27:30 +0000\tmaster-replica-0\t\tRunning module friday_training.train.\n",
      "INFO\t2019-07-31 20:27:30 +0000\tmaster-replica-0\t\tDownloading the package: gs://friday_demo2/friday_job_dir/packages/1954ba646e37bebd919cb50e2e5f2c36fcba8f4c7a713346c38b2c477223f738/friday_training-0.0.0.tar.gz\n",
      "INFO\t2019-07-31 20:27:30 +0000\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://friday_demo2/friday_job_dir/packages/1954ba646e37bebd919cb50e2e5f2c36fcba8f4c7a713346c38b2c477223f738/friday_training-0.0.0.tar.gz friday_training-0.0.0.tar.gz\n",
      "INFO\t2019-07-31 20:27:32 +0000\tmaster-replica-0\t\tInstalling the package: gs://friday_demo2/friday_job_dir/packages/1954ba646e37bebd919cb50e2e5f2c36fcba8f4c7a713346c38b2c477223f738/friday_training-0.0.0.tar.gz\n",
      "INFO\t2019-07-31 20:27:32 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps friday_training-0.0.0.tar.gz\n",
      "INFO\t2019-07-31 20:27:34 +0000\tmaster-replica-0\t\tProcessing ./friday_training-0.0.0.tar.gz\n",
      "INFO\t2019-07-31 20:27:36 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-07-31 20:27:36 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-07-31 20:27:36 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: friday-training\n",
      "INFO\t2019-07-31 20:27:36 +0000\tmaster-replica-0\t\t  Building wheel for friday-training (setup.py): started\n",
      "INFO\t2019-07-31 20:27:36 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-07-31 20:27:36 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-07-31 20:27:36 +0000\tmaster-replica-0\t\t  Building wheel for friday-training (setup.py): finished with status 'done'\n",
      "INFO\t2019-07-31 20:27:36 +0000\tmaster-replica-0\t\t  Created wheel for friday-training: filename=friday_training-0.0.0-cp35-none-any.whl size=2898 sha256=18ecf13d262f0c1daf0247e078cbf11d5acf2b0f895c7b5487857a9e638438f6\n",
      "INFO\t2019-07-31 20:27:36 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1f/4c/18/901c5f61d16bf6a3bef92702ea9c89690ebb04014ffcd6320d\n",
      "INFO\t2019-07-31 20:27:36 +0000\tmaster-replica-0\t\tSuccessfully built friday-training\n",
      "INFO\t2019-07-31 20:27:36 +0000\tmaster-replica-0\t\tInstalling collected packages: friday-training\n",
      "INFO\t2019-07-31 20:27:36 +0000\tmaster-replica-0\t\tSuccessfully installed friday-training-0.0.0\n",
      "INFO\t2019-07-31 20:27:37 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user friday_training-0.0.0.tar.gz\n",
      "INFO\t2019-07-31 20:27:37 +0000\tmaster-replica-0\t\tProcessing ./friday_training-0.0.0.tar.gz\n",
      "INFO\t2019-07-31 20:27:37 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-07-31 20:27:37 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-07-31 20:27:38 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: friday-training\n",
      "INFO\t2019-07-31 20:27:38 +0000\tmaster-replica-0\t\t  Building wheel for friday-training (setup.py): started\n",
      "INFO\t2019-07-31 20:27:38 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-07-31 20:27:38 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-07-31 20:27:38 +0000\tmaster-replica-0\t\t  Building wheel for friday-training (setup.py): finished with status 'done'\n",
      "INFO\t2019-07-31 20:27:38 +0000\tmaster-replica-0\t\t  Created wheel for friday-training: filename=friday_training-0.0.0-cp35-none-any.whl size=2898 sha256=8baa9b14f629339185ff0a43b66f46ecbb5e11c71fd2c86443badc01d5810679\n",
      "INFO\t2019-07-31 20:27:38 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1f/4c/18/901c5f61d16bf6a3bef92702ea9c89690ebb04014ffcd6320d\n",
      "INFO\t2019-07-31 20:27:38 +0000\tmaster-replica-0\t\tSuccessfully built friday-training\n",
      "INFO\t2019-07-31 20:27:39 +0000\tmaster-replica-0\t\tInstalling collected packages: friday-training\n",
      "INFO\t2019-07-31 20:27:39 +0000\tmaster-replica-0\t\t  Found existing installation: friday-training 0.0.0\n",
      "INFO\t2019-07-31 20:27:39 +0000\tmaster-replica-0\t\t    Uninstalling friday-training-0.0.0:\n",
      "INFO\t2019-07-31 20:27:39 +0000\tmaster-replica-0\t\t      Successfully uninstalled friday-training-0.0.0\n",
      "INFO\t2019-07-31 20:27:39 +0000\tmaster-replica-0\t\tSuccessfully installed friday-training-0.0.0\n",
      "INFO\t2019-07-31 20:27:40 +0000\tmaster-replica-0\t\tRunning command: python3 -m friday_training.train --bucket-name friday_demo2 --job-dir gs://friday_demo2/friday_job_dir\n",
      "ERROR\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:48] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "ERROR\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\tA value is trying to be set on a copy of a slice from a DataFrame\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:49] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "ERROR\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\tSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:49] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "ERROR\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t  errors=errors)\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:49] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:50] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:50] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:50] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:51] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:51] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:51] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:52] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:52] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:53] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:53] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:53] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:54] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:54] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:54] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:55] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\t[20:32:55] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\tClean up finished.\n",
      "INFO\t2019-07-31 20:32:55 +0000\tmaster-replica-0\t\tTask completed successfully.\n",
      "endTime: '2019-07-31T20:36:09'\n",
      "jobId: friday_training_1564604710\n",
      "startTime: '2019-07-31T20:26:33'\n",
      "state: SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Submit the training job:\n",
    "!gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --job-dir gs://$BUCKET_NAME/friday_job_dir \\\n",
    "  --package-path ./friday_training \\\n",
    "  --module-name friday_training.train \\\n",
    "  --region us-east1 \\\n",
    "  --runtime-version=1.12 \\\n",
    "  --python-version=3.5 \\\n",
    "  --scale-tier BASIC \\\n",
    "  --stream-logs \\\n",
    "  -- \\\n",
    "  --bucket-name $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"BlackFridayPredictor\"\n",
    "VERSION_NAME = \"friday_predictor\"\n",
    "#VERSION_NAME = \"friday_predictor_{}\".format(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.ml-engine.models.create) Resource in project [ml-sandbox-1-191918] is the subject of a conflict: Field: model.name Error: A model with the same name already exists.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: A model with the same name already exists.\n",
      "    field: model.name\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine models create $MODEL_NAME --regions us-east1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "Creating version (this might take a few minutes)......done.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine versions create $VERSION_NAME \\\n",
    "  --model=$MODEL_NAME \\\n",
    "  --framework=xgboost \\\n",
    "  --origin=gs://$BUCKET_NAME/ \\\n",
    "  --python-version=3.5 \\\n",
    "  --runtime-version=1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "b = test_features_10.values.tolist()\n",
    "json_file = \"data.json\"\n",
    "\n",
    "with open(json_file, 'w', encoding='utf-8') as f:\n",
    "    for i in b:\n",
    "        instance = {\"input\": i}\n",
    "        json.dump(instance, f, sort_keys=True)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Age_Count</th>\n",
       "      <th>Occupation_Count</th>\n",
       "      <th>Product_Category_1_Count</th>\n",
       "      <th>Product_Category_2_Count</th>\n",
       "      <th>Product_Category_3_Count</th>\n",
       "      <th>Product_ID_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>550068</th>\n",
       "      <td>1000004</td>\n",
       "      <td>1216</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>64902</td>\n",
       "      <td>83667</td>\n",
       "      <td>200699</td>\n",
       "      <td>20230</td>\n",
       "      <td>541656</td>\n",
       "      <td>1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550069</th>\n",
       "      <td>1000009</td>\n",
       "      <td>1063</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>311554</td>\n",
       "      <td>57076</td>\n",
       "      <td>28791</td>\n",
       "      <td>37165</td>\n",
       "      <td>541656</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550070</th>\n",
       "      <td>1000010</td>\n",
       "      <td>2799</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>155898</td>\n",
       "      <td>67329</td>\n",
       "      <td>215950</td>\n",
       "      <td>78834</td>\n",
       "      <td>541656</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550071</th>\n",
       "      <td>1000010</td>\n",
       "      <td>1379</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>155898</td>\n",
       "      <td>67329</td>\n",
       "      <td>16756</td>\n",
       "      <td>8177</td>\n",
       "      <td>541656</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550072</th>\n",
       "      <td>1000011</td>\n",
       "      <td>535</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>311554</td>\n",
       "      <td>67329</td>\n",
       "      <td>16756</td>\n",
       "      <td>37165</td>\n",
       "      <td>13115</td>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550073</th>\n",
       "      <td>1000013</td>\n",
       "      <td>3407</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>64902</td>\n",
       "      <td>67329</td>\n",
       "      <td>34056</td>\n",
       "      <td>4123</td>\n",
       "      <td>39968</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550074</th>\n",
       "      <td>1000013</td>\n",
       "      <td>1480</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>64902</td>\n",
       "      <td>67329</td>\n",
       "      <td>200699</td>\n",
       "      <td>20230</td>\n",
       "      <td>39968</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550075</th>\n",
       "      <td>1000013</td>\n",
       "      <td>3617</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>64902</td>\n",
       "      <td>67329</td>\n",
       "      <td>34056</td>\n",
       "      <td>36705</td>\n",
       "      <td>16532</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550076</th>\n",
       "      <td>1000015</td>\n",
       "      <td>1543</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>311554</td>\n",
       "      <td>83667</td>\n",
       "      <td>7373</td>\n",
       "      <td>15054</td>\n",
       "      <td>46469</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550077</th>\n",
       "      <td>1000022</td>\n",
       "      <td>673</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>141209</td>\n",
       "      <td>17257</td>\n",
       "      <td>215950</td>\n",
       "      <td>78834</td>\n",
       "      <td>541656</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        User_ID  Product_ID  Gender  Age  Occupation  City_Category  \\\n",
       "550068  1000004        1216       1    4           7              1   \n",
       "550069  1000009        1063       1    2          17              2   \n",
       "550070  1000010        2799       0    3           1              1   \n",
       "550071  1000010        1379       0    3           1              1   \n",
       "550072  1000011         535       0    2           1              2   \n",
       "550073  1000013        3407       1    4           1              2   \n",
       "550074  1000013        1480       1    4           1              2   \n",
       "550075  1000013        3617       1    4           1              2   \n",
       "550076  1000015        1543       1    2           7              0   \n",
       "550077  1000022         673       1    1          15              0   \n",
       "\n",
       "        Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "550068                           2               1                   0   \n",
       "550069                           0               0                   2   \n",
       "550070                           4               1                   4   \n",
       "550071                           4               1                   3   \n",
       "550072                           1               0                   3   \n",
       "550073                           3               1                   1   \n",
       "550074                           3               1                   0   \n",
       "550075                           3               1                   1   \n",
       "550076                           1               0                   9   \n",
       "550077                           4               0                   4   \n",
       "\n",
       "        Product_Category_2  Product_Category_3  Age_Count  Occupation_Count  \\\n",
       "550068                  10                   0      64902             83667   \n",
       "550069                   4                   0     311554             57076   \n",
       "550070                  13                   0     155898             67329   \n",
       "550071                   8                   0     155898             67329   \n",
       "550072                   4                   9     311554             67329   \n",
       "550073                   2                  12      64902             67329   \n",
       "550074                  10                  12      64902             67329   \n",
       "550075                   3                   6      64902             67329   \n",
       "550076                  12                  13     311554             83667   \n",
       "550077                  13                   0     141209             17257   \n",
       "\n",
       "        Product_Category_1_Count  Product_Category_2_Count  \\\n",
       "550068                    200699                     20230   \n",
       "550069                     28791                     37165   \n",
       "550070                    215950                     78834   \n",
       "550071                     16756                      8177   \n",
       "550072                     16756                     37165   \n",
       "550073                     34056                      4123   \n",
       "550074                    200699                     20230   \n",
       "550075                     34056                     36705   \n",
       "550076                      7373                     15054   \n",
       "550077                    215950                     78834   \n",
       "\n",
       "        Product_Category_3_Count  Product_ID_Count  \n",
       "550068                    541656              1333  \n",
       "550069                    541656               371  \n",
       "550070                    541656               217  \n",
       "550071                    541656                23  \n",
       "550072                     13115               781  \n",
       "550073                     39968               413  \n",
       "550074                     39968               602  \n",
       "550075                     16532               242  \n",
       "550076                     46469               166  \n",
       "550077                    541656               523  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_10 = test_features.head(10)\n",
    "test_features_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "test_feat = test_features_10.values.tolist()\n",
    "#export = test_features_10.json('data.json', orient='record')\n",
    "json_data = json.dumps(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-a5bd03e24ce3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_features_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'record'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'json'"
     ]
    }
   ],
   "source": [
    "export = test_features_10.json('data.json', orient='record')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FORMAT=\"text\" # JSON data format\n",
    "INPUT_PATHS='data.json'\n",
    "OUTPUT_PATH='gs://$BUCKET_NAME/'\n",
    "MODEL_NAME = \"BlackFridayPredictor\"\n",
    "VERSION_NAME = \"friday_predictor\"\n",
    "REGION='us-east1'\n",
    "#now=$(date +\"%Y%m%d_%H%M%S\")\n",
    "JOB_NAME = \"friday_training_{}\".format(int(time.time()))\n",
    "MAX_WORKER_COUNT=\"20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16196.408203125, 10362.009765625]\n"
     ]
    }
   ],
   "source": [
    "INPUT_FILE=\"data.json\"\n",
    "\n",
    "!gcloud ai-platform predict --model $MODEL_NAME --version \\\n",
    "  $VERSION_NAME --json-instances $INPUT_FILE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $INPUT_FILE\n",
    "[1000004,1216,1,4,7,1,2,1,0,10,0,64902,83667,200699,20230,541656,1333]\n",
    "[1000009,1063,1,2,17,2,0,0,2,4,0,311554,57076,28791,37165,541656,371]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $INPUT_FILE\n",
    "[\"User_ID\",1000004,\"Product_ID\",1216,\"Gender\",1,\"Age\",4,\"Occupation\",7,\"City_Category\",1,\"Stay_In_Current_City_Years\",2,\"Marital_Status\",1,\"Product_Category_1\",0,\"Product_Category_2\",10,\"Product_Category_3\",0,\"Age_Count\",64902,\"Occupation_Count\",83667,\"Product_Category_1_Count\",200699,\"Product_Category_2_Count\",20230,\"Product_Category_3_Count\",541656,\"Product_ID_Count\",1333]\n",
    "[\"User_ID\",1000009,\"Product_ID\",1063,\"Gender\",1,\"Age\",2,\"Occupation\",17,\"City_Category\",2,\"Stay_In_Current_City_Years\",0,\"Marital_Status\",0,\"Product_Category_1\",2,\"Product_Category_2\",4,\"Product_Category_3\",0,\"Age_Count\",311554,\"Occupation_Count\",57076,\"Product_Category_1_Count\",28791,\"Product_Category_2_Count\",37165,\"Product_Category_3_Count\",541656,\"Product_ID_Count\",371]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install witwidget --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'witwidget'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-13abb6af0c99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwitwidget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'witwidget'"
     ]
    }
   ],
   "source": [
    "import witwidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
